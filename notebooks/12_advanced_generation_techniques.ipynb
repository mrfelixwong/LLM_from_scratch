{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Generation Techniques\n",
    "\n",
    "Welcome to advanced text generation! This notebook explores sophisticated techniques for generating high-quality text from transformer models.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you'll understand:\n",
    "1. **Sampling Strategies**: Beyond greedy decoding\n",
    "2. **Beam Search Variants**: Tree search for better outputs\n",
    "3. **Quality Metrics**: How to measure generation quality\n",
    "4. **Controllable Generation**: Steering model outputs\n",
    "5. **Advanced Techniques**: State-of-the-art generation methods\n",
    "\n",
    "Let's start by setting up our environment and loading our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import heapq\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our transformer components\n",
    "from src.model.transformer import GPTModel\n",
    "from src.data.tokenizer import CharacterTokenizer\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sampling Strategies\n",
    "\n",
    "Different sampling strategies can dramatically affect the quality and diversity of generated text:\n",
    "\n",
    "### Common Sampling Methods:\n",
    "1. **Greedy Decoding**: Always pick the most likely token\n",
    "2. **Random Sampling**: Sample from the full distribution\n",
    "3. **Top-k Sampling**: Sample from the top k most likely tokens\n",
    "4. **Top-p (Nucleus) Sampling**: Sample from tokens comprising top p probability mass\n",
    "5. **Temperature Scaling**: Control randomness with temperature\n",
    "6. **Repetition Penalty**: Discourage repetitive text\n",
    "\n",
    "Let's implement and compare these strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class AdvancedSampler:\n",
    "    \"\"\"Advanced sampling strategies for text generation.\"\"\"\n",
    "    \n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = len(tokenizer.vocab)\n",
    "    \n",
    "    def greedy_sample(self, logits: torch.Tensor) -> int:\n",
    "        \"\"\"Greedy sampling - always pick the most likely token.\"\"\"\n",
    "        return torch.argmax(logits, dim=-1).item()\n",
    "    \n",
    "    def random_sample(self, logits: torch.Tensor, temperature: float = 1.0) -> int:\n",
    "        \"\"\"Random sampling with temperature scaling.\"\"\"\n",
    "        scaled_logits = logits / temperature\n",
    "        probs = F.softmax(scaled_logits, dim=-1)\n",
    "        return torch.multinomial(probs, num_samples=1).item()\n",
    "    \n",
    "    def top_k_sample(self, logits: torch.Tensor, k: int = 50, temperature: float = 1.0) -> int:\n",
    "        \"\"\"Top-k sampling.\"\"\"\n",
    "        scaled_logits = logits / temperature\n",
    "        \n",
    "        # Get top-k values and indices\n",
    "        top_k_values, top_k_indices = torch.topk(scaled_logits, k)\n",
    "        \n",
    "        # Create a new tensor with only top-k values\n",
    "        top_k_probs = F.softmax(top_k_values, dim=-1)\n",
    "        \n",
    "        # Sample from top-k\n",
    "        sample_idx = torch.multinomial(top_k_probs, num_samples=1).item()\n",
    "        return top_k_indices[sample_idx].item()\n",
    "    \n",
    "    def top_p_sample(self, logits: torch.Tensor, p: float = 0.9, temperature: float = 1.0) -> int:\n",
    "        \"\"\"Top-p (nucleus) sampling.\"\"\"\n",
    "        scaled_logits = logits / temperature\n",
    "        probs = F.softmax(scaled_logits, dim=-1)\n",
    "        \n",
    "        # Sort probabilities in descending order\n",
    "        sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "        \n",
    "        # Calculate cumulative probabilities\n",
    "        cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "        \n",
    "        # Find the cutoff point where cumulative probability exceeds p\n",
    "        sorted_indices_to_remove = cumulative_probs > p\n",
    "        \n",
    "        # Keep at least one token\n",
    "        sorted_indices_to_remove[1:] = sorted_indices_to_remove[:-1].clone()\n",
    "        sorted_indices_to_remove[0] = False\n",
    "        \n",
    "        # Remove tokens\n",
    "        indices_to_remove = sorted_indices_to_remove.scatter(0, sorted_indices, sorted_indices_to_remove)\n",
    "        logits_filtered = scaled_logits.clone()\n",
    "        logits_filtered[indices_to_remove] = float('-inf')\n",
    "        \n",
    "        # Sample from filtered distribution\n",
    "        probs_filtered = F.softmax(logits_filtered, dim=-1)\n",
    "        return torch.multinomial(probs_filtered, num_samples=1).item()\n",
    "    \n",
    "    def repetition_penalty_sample(self, logits: torch.Tensor, generated_tokens: List[int], \n",
    "                                 penalty: float = 1.2, temperature: float = 1.0) -> int:\n",
    "        \"\"\"Apply repetition penalty to discourage repetitive text.\"\"\"\n",
    "        if not generated_tokens:\n",
    "            return self.random_sample(logits, temperature)\n",
    "        \n",
    "        # Apply repetition penalty\n",
    "        penalized_logits = logits.clone()\n",
    "        for token in set(generated_tokens):\n",
    "            if penalized_logits[token] > 0:\n",
    "                penalized_logits[token] /= penalty\n",
    "            else:\n",
    "                penalized_logits[token] *= penalty\n",
    "        \n",
    "        return self.random_sample(penalized_logits, temperature)\n",
    "    \n",
    "    def contrastive_search(self, logits: torch.Tensor, generated_tokens: List[int],\n",
    "                          alpha: float = 0.6, k: int = 4) -> int:\n",
    "        \"\"\"Contrastive search for coherent and diverse generation.\"\"\"\n",
    "        if len(generated_tokens) < 2:\n",
    "            return self.top_k_sample(logits, k=k)\n",
    "        \n",
    "        # Get top-k candidates\n",
    "        top_k_values, top_k_indices = torch.topk(logits, k)\n",
    "        top_k_probs = F.softmax(top_k_values, dim=-1)\n",
    "        \n",
    "        # Calculate degeneration penalty (similarity to previous tokens)\n",
    "        scores = []\n",
    "        for i, token_id in enumerate(top_k_indices):\n",
    "            # Confidence score\n",
    "            confidence = top_k_probs[i].item()\n",
    "            \n",
    "            # Degeneration penalty (simplified)\n",
    "            recent_tokens = generated_tokens[-10:]  # Look at last 10 tokens\n",
    "            repetition_count = recent_tokens.count(token_id.item())\n",
    "            degeneration = repetition_count / len(recent_tokens) if recent_tokens else 0\n",
    "            \n",
    "            # Combined score\n",
    "            score = alpha * confidence - (1 - alpha) * degeneration\n",
    "            scores.append(score)\n",
    "        \n",
    "        # Select token with highest score\n",
    "        best_idx = np.argmax(scores)\n",
    "        return top_k_indices[best_idx].item()\n",
    "\n",
    "def create_demo_model():\n",
    "    \"\"\"Create a simple model for demonstration.\"\"\"\n",
    "    config = {\n",
    "        'vocab_size': 100,\n",
    "        'd_model': 64,\n",
    "        'n_heads': 4,\n",
    "        'n_layers': 2,\n",
    "        'd_ff': 128,\n",
    "        'max_seq_len': 64,\n",
    "        'dropout': 0.1\n",
    "    }\n",
    "    \n",
    "    model = GPTModel(config).to(device)\n",
    "    \n",
    "    # Create simple tokenizer\n",
    "    vocab = {chr(i): i for i in range(32, 127)}  # ASCII printable characters\n",
    "    vocab['<PAD>'] = 0\n",
    "    vocab['<UNK>'] = 1\n",
    "    \n",
    "    class SimpleTokenizer:\n",
    "        def __init__(self, vocab):\n",
    "            self.vocab = vocab\n",
    "            self.idx_to_token = {v: k for k, v in vocab.items()}\n",
    "        \n",
    "        def encode(self, text):\n",
    "            return [self.vocab.get(char, 1) for char in text]\n",
    "        \n",
    "        def decode(self, tokens):\n",
    "            return ''.join([self.idx_to_token.get(token, '<UNK>') for token in tokens])\n",
    "    \n",
    "    tokenizer = SimpleTokenizer(vocab)\n",
    "    return model, tokenizer\n",
    "\n",
    "def generate_with_strategy(model, tokenizer, sampler, prompt: str, max_length: int = 100,\n",
    "                          strategy: str = 'greedy', **kwargs) -> str:\n",
    "    \"\"\"Generate text using specified sampling strategy.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode prompt\n",
    "    input_ids = tokenizer.encode(prompt)\n",
    "    generated = input_ids.copy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length - len(input_ids)):\n",
    "            # Prepare input\n",
    "            input_tensor = torch.tensor([generated], device=device)\n",
    "            \n",
    "            # Get logits\n",
    "            outputs = model(input_tensor)\n",
    "            logits = outputs[0, -1, :]  # Last token logits\n",
    "            \n",
    "            # Sample next token based on strategy\n",
    "            if strategy == 'greedy':\n",
    "                next_token = sampler.greedy_sample(logits)\n",
    "            elif strategy == 'random':\n",
    "                next_token = sampler.random_sample(logits, kwargs.get('temperature', 1.0))\n",
    "            elif strategy == 'top_k':\n",
    "                next_token = sampler.top_k_sample(logits, kwargs.get('k', 50), kwargs.get('temperature', 1.0))\n",
    "            elif strategy == 'top_p':\n",
    "                next_token = sampler.top_p_sample(logits, kwargs.get('p', 0.9), kwargs.get('temperature', 1.0))\n",
    "            elif strategy == 'repetition_penalty':\n",
    "                next_token = sampler.repetition_penalty_sample(logits, generated, \n",
    "                                                             kwargs.get('penalty', 1.2), \n",
    "                                                             kwargs.get('temperature', 1.0))\n",
    "            elif strategy == 'contrastive':\n",
    "                next_token = sampler.contrastive_search(logits, generated, \n",
    "                                                       kwargs.get('alpha', 0.6), \n",
    "                                                       kwargs.get('k', 4))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "            \n",
    "            generated.append(next_token)\n",
    "            \n",
    "            # Stop if we hit padding or unknown token\n",
    "            if next_token in [0, 1]:\n",
    "                break\n",
    "    \n",
    "    return tokenizer.decode(generated)\n",
    "\n",
    "def compare_sampling_strategies():\n",
    "    \"\"\"Compare different sampling strategies.\"\"\"\n",
    "    print(\"Comparing sampling strategies...\")\n",
    "    \n",
    "    model, tokenizer = create_demo_model()\n",
    "    sampler = AdvancedSampler(tokenizer)\n",
    "    \n",
    "    prompt = \"The future of AI\"\n",
    "    max_length = 50\n",
    "    \n",
    "    strategies = {\n",
    "        'Greedy': {'strategy': 'greedy'},\n",
    "        'Random (T=0.8)': {'strategy': 'random', 'temperature': 0.8},\n",
    "        'Random (T=1.2)': {'strategy': 'random', 'temperature': 1.2},\n",
    "        'Top-k (k=10)': {'strategy': 'top_k', 'k': 10, 'temperature': 0.8},\n",
    "        'Top-p (p=0.9)': {'strategy': 'top_p', 'p': 0.9, 'temperature': 0.8},\n",
    "        'Repetition Penalty': {'strategy': 'repetition_penalty', 'penalty': 1.2, 'temperature': 0.8},\n",
    "        'Contrastive Search': {'strategy': 'contrastive', 'alpha': 0.6, 'k': 4}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nPrompt: '{prompt}'\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    results = {}\n",
    "    for name, params in strategies.items():\n",
    "        # Generate multiple samples for diversity analysis\n",
    "        samples = []\n",
    "        for _ in range(3):\n",
    "            generated = generate_with_strategy(model, tokenizer, sampler, prompt, max_length, **params)\n",
    "            samples.append(generated)\n",
    "        \n",
    "        results[name] = samples\n",
    "        \n",
    "        print(f\"\\n{name}:\")\n",
    "        for i, sample in enumerate(samples, 1):\n",
    "            print(f\"  {i}: {sample}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Compare sampling strategies\n",
    "sampling_results = compare_sampling_strategies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Sampling Strategy Effects\n",
    "\n",
    "Let's visualize how different sampling strategies affect the probability distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualize_sampling_distributions():\n",
    "    \"\"\"Visualize how different sampling strategies modify probability distributions.\"\"\"\n",
    "    # Create a synthetic probability distribution\n",
    "    vocab_size = 50\n",
    "    logits = torch.randn(vocab_size) * 2  # Random logits\n",
    "    logits[0] = 5.0  # Make first token very likely\n",
    "    logits[1] = 3.0  # Second most likely\n",
    "    logits[2] = 2.0  # Third most likely\n",
    "    \n",
    "    original_probs = F.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Apply different sampling strategies\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Original distribution\n",
    "    axes[0, 0].bar(range(vocab_size), original_probs.numpy())\n",
    "    axes[0, 0].set_title('Original Distribution')\n",
    "    axes[0, 0].set_xlabel('Token Index')\n",
    "    axes[0, 0].set_ylabel('Probability')\n",
    "    axes[0, 0].set_xlim(0, 20)  # Show only first 20 tokens\n",
    "    \n",
    "    # Temperature scaling\n",
    "    temperatures = [0.5, 1.0, 2.0]\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    for temp, color in zip(temperatures, colors):\n",
    "        temp_probs = F.softmax(logits / temp, dim=-1)\n",
    "        axes[0, 1].plot(range(20), temp_probs[:20].numpy(), \n",
    "                       label=f'T={temp}', color=color, linewidth=2)\n",
    "    axes[0, 1].set_title('Temperature Scaling Effect')\n",
    "    axes[0, 1].set_xlabel('Token Index')\n",
    "    axes[0, 1].set_ylabel('Probability')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Top-k filtering\n",
    "    k_values = [5, 10, 15]\n",
    "    for k, color in zip(k_values, colors):\n",
    "        top_k_values, top_k_indices = torch.topk(logits, k)\n",
    "        k_probs = torch.zeros_like(logits)\n",
    "        k_probs[top_k_indices] = F.softmax(top_k_values, dim=-1)\n",
    "        axes[0, 2].bar(range(20), k_probs[:20].numpy(), \n",
    "                      alpha=0.7, label=f'k={k}', color=color)\n",
    "    axes[0, 2].set_title('Top-k Filtering Effect')\n",
    "    axes[0, 2].set_xlabel('Token Index')\n",
    "    axes[0, 2].set_ylabel('Probability')\n",
    "    axes[0, 2].legend()\n",
    "    \n",
    "    # Top-p filtering\n",
    "    p_values = [0.5, 0.8, 0.95]\n",
    "    for p, color in zip(p_values, colors):\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "        cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "        \n",
    "        # Find cutoff\n",
    "        sorted_indices_to_remove = cumulative_probs > p\n",
    "        sorted_indices_to_remove[1:] = sorted_indices_to_remove[:-1].clone()\n",
    "        sorted_indices_to_remove[0] = False\n",
    "        \n",
    "        # Create filtered distribution\n",
    "        p_probs = probs.clone()\n",
    "        indices_to_remove = sorted_indices_to_remove.scatter(0, sorted_indices, sorted_indices_to_remove)\n",
    "        p_probs[indices_to_remove] = 0\n",
    "        p_probs = p_probs / p_probs.sum()  # Renormalize\n",
    "        \n",
    "        axes[1, 0].bar(range(20), p_probs[:20].numpy(), \n",
    "                      alpha=0.7, label=f'p={p}', color=color)\n",
    "    axes[1, 0].set_title('Top-p (Nucleus) Filtering Effect')\n",
    "    axes[1, 0].set_xlabel('Token Index')\n",
    "    axes[1, 0].set_ylabel('Probability')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Repetition penalty simulation\n",
    "    penalties = [1.0, 1.2, 1.5]\n",
    "    repeated_tokens = [0, 1, 2]  # Assume these tokens were recently generated\n",
    "    \n",
    "    for penalty, color in zip(penalties, colors):\n",
    "        penalized_logits = logits.clone()\n",
    "        for token in repeated_tokens:\n",
    "            if penalized_logits[token] > 0:\n",
    "                penalized_logits[token] /= penalty\n",
    "            else:\n",
    "                penalized_logits[token] *= penalty\n",
    "        \n",
    "        penalty_probs = F.softmax(penalized_logits, dim=-1)\n",
    "        axes[1, 1].bar(range(20), penalty_probs[:20].numpy(), \n",
    "                      alpha=0.7, label=f'penalty={penalty}', color=color)\n",
    "    axes[1, 1].set_title('Repetition Penalty Effect')\n",
    "    axes[1, 1].set_xlabel('Token Index')\n",
    "    axes[1, 1].set_ylabel('Probability')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    # Diversity vs quality tradeoff\n",
    "    methods = ['Greedy', 'Top-k=5', 'Top-k=50', 'Top-p=0.5', 'Top-p=0.9', 'Random']\n",
    "    quality_scores = [0.9, 0.85, 0.7, 0.8, 0.65, 0.4]  # Simulated quality scores\n",
    "    diversity_scores = [0.1, 0.3, 0.6, 0.4, 0.7, 0.9]  # Simulated diversity scores\n",
    "    \n",
    "    axes[1, 2].scatter(diversity_scores, quality_scores, s=100, alpha=0.7)\n",
    "    for i, method in enumerate(methods):\n",
    "        axes[1, 2].annotate(method, (diversity_scores[i], quality_scores[i]), \n",
    "                           xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "    \n",
    "    axes[1, 2].set_xlabel('Diversity Score')\n",
    "    axes[1, 2].set_ylabel('Quality Score')\n",
    "    axes[1, 2].set_title('Quality vs Diversity Tradeoff')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    axes[1, 2].set_xlim(0, 1)\n",
    "    axes[1, 2].set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nSampling Strategy Guidelines:\")\n",
    "    print(\"• Greedy: Deterministic, highest quality, lowest diversity\")\n",
    "    print(\"• Low temperature (0.5-0.8): More focused, higher quality\")\n",
    "    print(\"• High temperature (1.2-2.0): More random, higher diversity\")\n",
    "    print(\"• Top-k (small k): Balanced quality/diversity\")\n",
    "    print(\"• Top-p (0.9): Good default for most applications\")\n",
    "    print(\"• Repetition penalty: Reduces repetition, maintains coherence\")\n",
    "\n",
    "# Visualize sampling distributions\n",
    "visualize_sampling_distributions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Beam Search and Variants\n",
    "\n",
    "Beam search explores multiple possible sequences simultaneously, keeping track of the most promising candidates.\n",
    "\n",
    "### Beam Search Variants:\n",
    "1. **Standard Beam Search**: Keep top-k sequences\n",
    "2. **Diverse Beam Search**: Encourage diversity among beams\n",
    "3. **Constrained Beam Search**: Enforce specific constraints\n",
    "4. **Length Normalization**: Adjust scores by sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class BeamSearchDecoder:\n",
    "    \"\"\"Beam search decoder with various enhancements.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, beam_size: int = 5):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.beam_size = beam_size\n",
    "        self.device = next(model.parameters()).device\n",
    "    \n",
    "    def beam_search(self, prompt: str, max_length: int = 100, \n",
    "                   length_penalty: float = 1.0, \n",
    "                   early_stopping: bool = True,\n",
    "                   repetition_penalty: float = 1.0) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Standard beam search.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Encode prompt\n",
    "        input_ids = self.tokenizer.encode(prompt)\n",
    "        \n",
    "        # Initialize beams: (sequence, score, finished)\n",
    "        beams = [(input_ids, 0.0, False)]\n",
    "        finished_beams = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step in range(max_length - len(input_ids)):\n",
    "                candidates = []\n",
    "                \n",
    "                for sequence, score, finished in beams:\n",
    "                    if finished:\n",
    "                        candidates.append((sequence, score, True))\n",
    "                        continue\n",
    "                    \n",
    "                    # Get next token probabilities\n",
    "                    input_tensor = torch.tensor([sequence], device=self.device)\n",
    "                    outputs = self.model(input_tensor)\n",
    "                    logits = outputs[0, -1, :]\n",
    "                    \n",
    "                    # Apply repetition penalty\n",
    "                    if repetition_penalty != 1.0:\n",
    "                        for token in set(sequence):\n",
    "                            if logits[token] > 0:\n",
    "                                logits[token] /= repetition_penalty\n",
    "                            else:\n",
    "                                logits[token] *= repetition_penalty\n",
    "                    \n",
    "                    log_probs = F.log_softmax(logits, dim=-1)\n",
    "                    \n",
    "                    # Get top beam_size tokens\n",
    "                    top_log_probs, top_indices = torch.topk(log_probs, self.beam_size)\n",
    "                    \n",
    "                    for log_prob, token_id in zip(top_log_probs, top_indices):\n",
    "                        new_sequence = sequence + [token_id.item()]\n",
    "                        new_score = score + log_prob.item()\n",
    "                        \n",
    "                        # Check if sequence is finished (simplified - check for padding)\n",
    "                        finished = token_id.item() == 0 or len(new_sequence) >= max_length\n",
    "                        \n",
    "                        candidates.append((new_sequence, new_score, finished))\n",
    "                \n",
    "                # Select top beam_size candidates\n",
    "                candidates.sort(key=lambda x: self._length_normalize(x[1], len(x[0]), length_penalty), reverse=True)\n",
    "                \n",
    "                # Separate finished and unfinished beams\n",
    "                beams = []\n",
    "                for seq, score, finished in candidates:\n",
    "                    if finished:\n",
    "                        finished_beams.append((seq, score))\n",
    "                    else:\n",
    "                        beams.append((seq, score, finished))\n",
    "                    \n",
    "                    if len(beams) >= self.beam_size:\n",
    "                        break\n",
    "                \n",
    "                # Early stopping if we have enough finished beams\n",
    "                if early_stopping and len(finished_beams) >= self.beam_size:\n",
    "                    break\n",
    "        \n",
    "        # Add remaining beams to finished\n",
    "        for seq, score, _ in beams:\n",
    "            finished_beams.append((seq, score))\n",
    "        \n",
    "        # Sort by normalized score and return\n",
    "        finished_beams.sort(key=lambda x: self._length_normalize(x[1], len(x[0]), length_penalty), reverse=True)\n",
    "        \n",
    "        # Convert to text\n",
    "        results = []\n",
    "        for seq, score in finished_beams[:self.beam_size]:\n",
    "            text = self.tokenizer.decode(seq)\n",
    "            normalized_score = self._length_normalize(score, len(seq), length_penalty)\n",
    "            results.append((text, normalized_score))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def diverse_beam_search(self, prompt: str, max_length: int = 100,\n",
    "                           num_groups: int = 2, diversity_penalty: float = 0.5,\n",
    "                           length_penalty: float = 1.0) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Diverse beam search to encourage variety in outputs.\"\"\"\n",
    "        # Simplified implementation\n",
    "        group_size = self.beam_size // num_groups\n",
    "        all_results = []\n",
    "        \n",
    "        for group in range(num_groups):\n",
    "            # Create a temporary decoder for this group\n",
    "            group_decoder = BeamSearchDecoder(self.model, self.tokenizer, group_size)\n",
    "            \n",
    "            # Get results for this group\n",
    "            group_results = group_decoder.beam_search(prompt, max_length, length_penalty)\n",
    "            \n",
    "            # Apply diversity penalty based on previous groups\n",
    "            penalized_results = []\n",
    "            for text, score in group_results:\n",
    "                # Simple diversity penalty: penalize overlap with previous groups\n",
    "                diversity_score = 0\n",
    "                for prev_text, _ in all_results:\n",
    "                    # Calculate simple overlap penalty\n",
    "                    overlap = len(set(text.split()) & set(prev_text.split()))\n",
    "                    diversity_score += overlap * diversity_penalty\n",
    "                \n",
    "                adjusted_score = score - diversity_score\n",
    "                penalized_results.append((text, adjusted_score))\n",
    "            \n",
    "            all_results.extend(penalized_results)\n",
    "        \n",
    "        # Sort and return top results\n",
    "        all_results.sort(key=lambda x: x[1], reverse=True)\n",
    "        return all_results[:self.beam_size]\n",
    "    \n",
    "    def constrained_beam_search(self, prompt: str, constraints: List[str],\n",
    "                               max_length: int = 100) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Beam search with constraints (must include certain words/phrases).\"\"\"\n",
    "        # Simplified implementation - check if constraints are satisfied\n",
    "        results = self.beam_search(prompt, max_length)\n",
    "        \n",
    "        # Filter results that satisfy constraints\n",
    "        constrained_results = []\n",
    "        for text, score in results:\n",
    "            satisfies_constraints = all(constraint.lower() in text.lower() \n",
    "                                      for constraint in constraints)\n",
    "            if satisfies_constraints:\n",
    "                constrained_results.append((text, score))\n",
    "        \n",
    "        return constrained_results if constrained_results else results\n",
    "    \n",
    "    def _length_normalize(self, score: float, length: int, alpha: float) -> float:\n",
    "        \"\"\"Apply length normalization to beam search scores.\"\"\"\n",
    "        if alpha == 0:\n",
    "            return score\n",
    "        return score / (length ** alpha)\n",
    "\n",
    "def demonstrate_beam_search():\n",
    "    \"\"\"Demonstrate different beam search variants.\"\"\"\n",
    "    print(\"Demonstrating beam search variants...\")\n",
    "    \n",
    "    model, tokenizer = create_demo_model()\n",
    "    decoder = BeamSearchDecoder(model, tokenizer, beam_size=5)\n",
    "    \n",
    "    prompt = \"The future of technology\"\n",
    "    max_length = 60\n",
    "    \n",
    "    print(f\"\\nPrompt: '{prompt}'\\n\")\n",
    "    \n",
    "    # Standard beam search\n",
    "    print(\"=== Standard Beam Search ===\")\n",
    "    standard_results = decoder.beam_search(prompt, max_length)\n",
    "    for i, (text, score) in enumerate(standard_results, 1):\n",
    "        print(f\"{i}. (Score: {score:.3f}) {text}\")\n",
    "    \n",
    "    # Beam search with length penalty\n",
    "    print(\"\\n=== Beam Search with Length Penalty ===\")\n",
    "    length_results = decoder.beam_search(prompt, max_length, length_penalty=0.8)\n",
    "    for i, (text, score) in enumerate(length_results, 1):\n",
    "        print(f\"{i}. (Score: {score:.3f}) {text}\")\n",
    "    \n",
    "    # Diverse beam search\n",
    "    print(\"\\n=== Diverse Beam Search ===\")\n",
    "    diverse_results = decoder.diverse_beam_search(prompt, max_length, num_groups=2)\n",
    "    for i, (text, score) in enumerate(diverse_results, 1):\n",
    "        print(f\"{i}. (Score: {score:.3f}) {text}\")\n",
    "    \n",
    "    # Constrained beam search\n",
    "    print(\"\\n=== Constrained Beam Search (must include 'innovation') ===\")\n",
    "    constrained_results = decoder.constrained_beam_search(prompt, ['innovation'], max_length)\n",
    "    for i, (text, score) in enumerate(constrained_results, 1):\n",
    "        print(f\"{i}. (Score: {score:.3f}) {text}\")\n",
    "    \n",
    "    return {\n",
    "        'standard': standard_results,\n",
    "        'length_penalty': length_results,\n",
    "        'diverse': diverse_results,\n",
    "        'constrained': constrained_results\n",
    "    }\n",
    "\n",
    "# Demonstrate beam search\n",
    "beam_results = demonstrate_beam_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quality Metrics for Generated Text\n",
    "\n",
    "Measuring the quality of generated text is crucial for comparing different generation methods:\n",
    "\n",
    "### Common Quality Metrics:\n",
    "1. **Perplexity**: How well the model predicts the text\n",
    "2. **BLEU Score**: N-gram overlap with reference text\n",
    "3. **ROUGE Score**: Recall-oriented overlap metrics\n",
    "4. **Diversity Metrics**: Unique n-grams, repetition ratio\n",
    "5. **Coherence Metrics**: Semantic consistency\n",
    "6. **Fluency Metrics**: Language model confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class TextQualityEvaluator:\n",
    "    \"\"\"Evaluate quality of generated text using various metrics.\"\"\"\n",
    "    \n",
    "    def __init__(self, model=None, tokenizer=None):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def calculate_perplexity(self, text: str) -> float:\n",
    "        \"\"\"Calculate perplexity of text using the model.\"\"\"\n",
    "        if not self.model or not self.tokenizer:\n",
    "            return float('inf')\n",
    "        \n",
    "        self.model.eval()\n",
    "        tokens = self.tokenizer.encode(text)\n",
    "        \n",
    "        if len(tokens) < 2:\n",
    "            return float('inf')\n",
    "        \n",
    "        total_log_prob = 0.0\n",
    "        num_tokens = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(1, len(tokens)):\n",
    "                context = tokens[:i]\n",
    "                target = tokens[i]\n",
    "                \n",
    "                input_tensor = torch.tensor([context], device=next(self.model.parameters()).device)\n",
    "                outputs = self.model(input_tensor)\n",
    "                logits = outputs[0, -1, :]\n",
    "                \n",
    "                log_probs = F.log_softmax(logits, dim=-1)\n",
    "                total_log_prob += log_probs[target].item()\n",
    "                num_tokens += 1\n",
    "        \n",
    "        avg_log_prob = total_log_prob / num_tokens\n",
    "        perplexity = torch.exp(-torch.tensor(avg_log_prob)).item()\n",
    "        \n",
    "        return perplexity\n",
    "    \n",
    "    def calculate_bleu_score(self, generated: str, reference: str, n_gram: int = 4) -> float:\n",
    "        \"\"\"Calculate BLEU score (simplified implementation).\"\"\"\n",
    "        generated_tokens = generated.lower().split()\n",
    "        reference_tokens = reference.lower().split()\n",
    "        \n",
    "        if len(generated_tokens) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate n-gram precision for different n\n",
    "        precisions = []\n",
    "        for n in range(1, n_gram + 1):\n",
    "            gen_ngrams = self._get_ngrams(generated_tokens, n)\n",
    "            ref_ngrams = self._get_ngrams(reference_tokens, n)\n",
    "            \n",
    "            if len(gen_ngrams) == 0:\n",
    "                precisions.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            matches = 0\n",
    "            for ngram in gen_ngrams:\n",
    "                if ngram in ref_ngrams:\n",
    "                    matches += min(gen_ngrams[ngram], ref_ngrams[ngram])\n",
    "            \n",
    "            precision = matches / sum(gen_ngrams.values())\n",
    "            precisions.append(precision)\n",
    "        \n",
    "        # Geometric mean of precisions\n",
    "        if any(p == 0 for p in precisions):\n",
    "            return 0.0\n",
    "        \n",
    "        geometric_mean = np.exp(np.mean([np.log(p) for p in precisions]))\n",
    "        \n",
    "        # Brevity penalty\n",
    "        bp = min(1.0, np.exp(1 - len(reference_tokens) / len(generated_tokens)))\n",
    "        \n",
    "        return bp * geometric_mean\n",
    "    \n",
    "    def calculate_diversity_metrics(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Calculate diversity metrics for generated text.\"\"\"\n",
    "        tokens = text.lower().split()\n",
    "        \n",
    "        if len(tokens) == 0:\n",
    "            return {'distinct_1': 0.0, 'distinct_2': 0.0, 'repetition_ratio': 1.0}\n",
    "        \n",
    "        # Distinct n-grams\n",
    "        unigrams = set(tokens)\n",
    "        bigrams = set(zip(tokens[:-1], tokens[1:])) if len(tokens) > 1 else set()\n",
    "        \n",
    "        distinct_1 = len(unigrams) / len(tokens)\n",
    "        distinct_2 = len(bigrams) / max(1, len(tokens) - 1)\n",
    "        \n",
    "        # Repetition ratio\n",
    "        token_counts = Counter(tokens)\n",
    "        repeated_tokens = sum(count - 1 for count in token_counts.values() if count > 1)\n",
    "        repetition_ratio = repeated_tokens / len(tokens)\n",
    "        \n",
    "        return {\n",
    "            'distinct_1': distinct_1,\n",
    "            'distinct_2': distinct_2,\n",
    "            'repetition_ratio': repetition_ratio,\n",
    "            'unique_tokens': len(unigrams),\n",
    "            'total_tokens': len(tokens)\n",
    "        }\n",
    "    \n",
    "    def calculate_coherence_score(self, text: str) -> float:\n",
    "        \"\"\"Calculate coherence score (simplified implementation).\"\"\"\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "        \n",
    "        if len(sentences) < 2:\n",
    "            return 1.0  # Single sentence is considered coherent\n",
    "        \n",
    "        # Simple coherence metric: overlap between consecutive sentences\n",
    "        coherence_scores = []\n",
    "        for i in range(len(sentences) - 1):\n",
    "            sent1_words = set(sentences[i].lower().split())\n",
    "            sent2_words = set(sentences[i + 1].lower().split())\n",
    "            \n",
    "            if len(sent1_words) == 0 or len(sent2_words) == 0:\n",
    "                coherence_scores.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            overlap = len(sent1_words & sent2_words)\n",
    "            coherence = overlap / min(len(sent1_words), len(sent2_words))\n",
    "            coherence_scores.append(coherence)\n",
    "        \n",
    "        return np.mean(coherence_scores) if coherence_scores else 0.0\n",
    "    \n",
    "    def _get_ngrams(self, tokens: List[str], n: int) -> Dict[tuple, int]:\n",
    "        \"\"\"Get n-gram counts from tokens.\"\"\"\n",
    "        ngrams = defaultdict(int)\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ngram = tuple(tokens[i:i + n])\n",
    "            ngrams[ngram] += 1\n",
    "        return dict(ngrams)\n",
    "    \n",
    "    def evaluate_text(self, text: str, reference: str = None) -> Dict[str, float]:\n",
    "        \"\"\"Comprehensive evaluation of generated text.\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Perplexity\n",
    "        metrics['perplexity'] = self.calculate_perplexity(text)\n",
    "        \n",
    "        # BLEU score (if reference provided)\n",
    "        if reference:\n",
    "            metrics['bleu_score'] = self.calculate_bleu_score(text, reference)\n",
    "        \n",
    "        # Diversity metrics\n",
    "        diversity = self.calculate_diversity_metrics(text)\n",
    "        metrics.update(diversity)\n",
    "        \n",
    "        # Coherence\n",
    "        metrics['coherence'] = self.calculate_coherence_score(text)\n",
    "        \n",
    "        # Length\n",
    "        metrics['length'] = len(text.split())\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "def compare_generation_quality():\n",
    "    \"\"\"Compare quality of different generation methods.\"\"\"\n",
    "    print(\"Comparing generation quality across different methods...\")\n",
    "    \n",
    "    model, tokenizer = create_demo_model()\n",
    "    evaluator = TextQualityEvaluator(model, tokenizer)\n",
    "    \n",
    "    # Generate sample texts using different methods\n",
    "    prompt = \"The future of artificial intelligence\"\n",
    "    reference = \"The future of artificial intelligence holds great promise for advancing human knowledge and capabilities through innovative technologies and ethical applications.\"\n",
    "    \n",
    "    # Sample generated texts (in practice, these would come from your generation methods)\n",
    "    generated_texts = {\n",
    "        'Greedy': \"The future of artificial intelligence is very important and will be very good for everyone.\",\n",
    "        'Top-k': \"The future of artificial intelligence promises exciting developments in machine learning and automation.\",\n",
    "        'Top-p': \"The future of artificial intelligence involves complex algorithms, neural networks, and innovative solutions.\",\n",
    "        'Beam Search': \"The future of artificial intelligence encompasses revolutionary technologies that enhance human capabilities.\",\n",
    "        'Random': \"The future artificial intelligence computer science technology innovation development research applications.\"\n",
    "    }\n",
    "    \n",
    "    # Evaluate each method\n",
    "    results = {}\n",
    "    for method, text in generated_texts.items():\n",
    "        metrics = evaluator.evaluate_text(text, reference)\n",
    "        results[method] = metrics\n",
    "        \n",
    "        print(f\"\\n{method}:\")\n",
    "        print(f\"  Text: {text}\")\n",
    "        print(f\"  Perplexity: {metrics['perplexity']:.2f}\")\n",
    "        print(f\"  BLEU Score: {metrics['bleu_score']:.3f}\")\n",
    "        print(f\"  Distinct-1: {metrics['distinct_1']:.3f}\")\n",
    "        print(f\"  Distinct-2: {metrics['distinct_2']:.3f}\")\n",
    "        print(f\"  Repetition Ratio: {metrics['repetition_ratio']:.3f}\")\n",
    "        print(f\"  Coherence: {metrics['coherence']:.3f}\")\n",
    "    \n",
    "    # Create comparison visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    methods = list(results.keys())\n",
    "    metrics_to_plot = ['bleu_score', 'distinct_1', 'distinct_2', 'coherence', 'repetition_ratio', 'length']\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_to_plot):\n",
    "        ax = axes[idx // 3, idx % 3]\n",
    "        values = [results[method][metric] for method in methods]\n",
    "        \n",
    "        bars = ax.bar(methods, values, alpha=0.7)\n",
    "        ax.set_title(f'{metric.replace(\"_\", \" \").title()}')\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{value:.3f}',\n",
    "                       xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                       xytext=(0, 3),  # 3 points vertical offset\n",
    "                       textcoords=\"offset points\",\n",
    "                       ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create radar plot for comprehensive comparison\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "    \n",
    "    # Normalize metrics to 0-1 scale for radar plot\n",
    "    radar_metrics = ['bleu_score', 'distinct_1', 'coherence']\n",
    "    angles = np.linspace(0, 2 * np.pi, len(radar_metrics), endpoint=False)\n",
    "    angles = np.concatenate((angles, [angles[0]]))  # Complete the circle\n",
    "    \n",
    "    for method in methods:\n",
    "        values = [results[method][metric] for metric in radar_metrics]\n",
    "        values += [values[0]]  # Complete the circle\n",
    "        \n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label=method)\n",
    "        ax.fill(angles, values, alpha=0.25)\n",
    "    \n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels([metric.replace('_', ' ').title() for metric in radar_metrics])\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('Generation Quality Comparison (Radar Plot)', size=16, pad=20)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Compare generation quality\n",
    "quality_results = compare_generation_quality()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Controllable Generation Techniques\n",
    "\n",
    "Controllable generation allows us to steer the model's output towards desired characteristics:\n",
    "\n",
    "### Controllable Generation Methods:\n",
    "1. **Prompt Engineering**: Crafting effective prompts\n",
    "2. **Prefix Tuning**: Adding learnable prefix tokens\n",
    "3. **Guided Generation**: Using external classifiers\n",
    "4. **Attribute Control**: Controlling specific attributes (sentiment, style)\n",
    "5. **Structural Control**: Controlling format and structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class ControllableGenerator:\n",
    "    \"\"\"Controllable text generation with various steering mechanisms.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, sampler):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sampler = sampler\n",
    "        self.device = next(model.parameters()).device\n",
    "    \n",
    "    def generate_with_length_control(self, prompt: str, target_length: int, \n",
    "                                   tolerance: int = 5) -> str:\n",
    "        \"\"\"Generate text with specific length control.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        input_ids = self.tokenizer.encode(prompt)\n",
    "        generated = input_ids.copy()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            while len(generated) < target_length + tolerance:\n",
    "                input_tensor = torch.tensor([generated], device=self.device)\n",
    "                outputs = self.model(input_tensor)\n",
    "                logits = outputs[0, -1, :]\n",
    "                \n",
    "                # Adjust sampling based on remaining length\n",
    "                remaining_length = target_length - len(generated)\n",
    "                if remaining_length <= tolerance:\n",
    "                    # Near target length - be more selective\n",
    "                    next_token = self.sampler.top_p_sample(logits, p=0.5, temperature=0.7)\n",
    "                else:\n",
    "                    # Still need more tokens - be more creative\n",
    "                    next_token = self.sampler.top_p_sample(logits, p=0.9, temperature=1.0)\n",
    "                \n",
    "                generated.append(next_token)\n",
    "                \n",
    "                # Early stopping conditions\n",
    "                if next_token in [0, 1]:  # padding or unknown\n",
    "                    break\n",
    "        \n",
    "        return self.tokenizer.decode(generated)\n",
    "    \n",
    "    def generate_with_keyword_control(self, prompt: str, required_keywords: List[str],\n",
    "                                    max_length: int = 100) -> str:\n",
    "        \"\"\"Generate text that includes specific keywords.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        input_ids = self.tokenizer.encode(prompt)\n",
    "        generated = input_ids.copy()\n",
    "        used_keywords = set()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step in range(max_length - len(input_ids)):\n",
    "                input_tensor = torch.tensor([generated], device=self.device)\n",
    "                outputs = self.model(input_tensor)\n",
    "                logits = outputs[0, -1, :]\n",
    "                \n",
    "                # Boost probabilities of keyword tokens\n",
    "                current_text = self.tokenizer.decode(generated)\n",
    "                unused_keywords = [kw for kw in required_keywords if kw not in used_keywords]\n",
    "                \n",
    "                if unused_keywords and step > 10:  # Don't force keywords too early\n",
    "                    # Simple keyword boosting (this is a simplified approach)\n",
    "                    for keyword in unused_keywords:\n",
    "                        keyword_tokens = self.tokenizer.encode(keyword)\n",
    "                        for token in keyword_tokens:\n",
    "                            if token < len(logits):\n",
    "                                logits[token] += 2.0  # Boost keyword tokens\n",
    "                \n",
    "                next_token = self.sampler.top_p_sample(logits, p=0.9, temperature=0.8)\n",
    "                generated.append(next_token)\n",
    "                \n",
    "                # Check if we've used any new keywords\n",
    "                current_text = self.tokenizer.decode(generated)\n",
    "                for keyword in required_keywords:\n",
    "                    if keyword.lower() in current_text.lower():\n",
    "                        used_keywords.add(keyword)\n",
    "                \n",
    "                if next_token in [0, 1]:\n",
    "                    break\n",
    "        \n",
    "        return self.tokenizer.decode(generated)\n",
    "    \n",
    "    def generate_with_sentiment_control(self, prompt: str, target_sentiment: str,\n",
    "                                      max_length: int = 100) -> str:\n",
    "        \"\"\"Generate text with controlled sentiment (simplified).\"\"\"\n",
    "        # Sentiment word lists (simplified)\n",
    "        positive_words = ['good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic']\n",
    "        negative_words = ['bad', 'terrible', 'awful', 'horrible', 'disappointing', 'poor']\n",
    "        \n",
    "        self.model.eval()\n",
    "        input_ids = self.tokenizer.encode(prompt)\n",
    "        generated = input_ids.copy()\n",
    "        \n",
    "        target_words = positive_words if target_sentiment.lower() == 'positive' else negative_words\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step in range(max_length - len(input_ids)):\n",
    "                input_tensor = torch.tensor([generated], device=self.device)\n",
    "                outputs = self.model(input_tensor)\n",
    "                logits = outputs[0, -1, :]\n",
    "                \n",
    "                # Boost sentiment-appropriate words\n",
    "                if step > 5:  # Allow some context to build first\n",
    "                    for word in target_words:\n",
    "                        word_tokens = self.tokenizer.encode(word)\n",
    "                        for token in word_tokens:\n",
    "                            if token < len(logits):\n",
    "                                logits[token] += 1.5\n",
    "                \n",
    "                next_token = self.sampler.top_p_sample(logits, p=0.9, temperature=0.8)\n",
    "                generated.append(next_token)\n",
    "                \n",
    "                if next_token in [0, 1]:\n",
    "                    break\n",
    "        \n",
    "        return self.tokenizer.decode(generated)\n",
    "    \n",
    "    def generate_with_format_control(self, prompt: str, format_type: str,\n",
    "                                   max_length: int = 100) -> str:\n",
    "        \"\"\"Generate text with specific format control.\"\"\"\n",
    "        format_prompts = {\n",
    "            'list': prompt + \" Here is a list:\\n1.\",\n",
    "            'question': prompt + \" Here are some questions:\\nQ:\",\n",
    "            'summary': prompt + \" In summary,\",\n",
    "            'story': prompt + \" Once upon a time,\",\n",
    "            'dialogue': prompt + \" Person A said:\"\n",
    "        }\n",
    "        \n",
    "        enhanced_prompt = format_prompts.get(format_type, prompt)\n",
    "        \n",
    "        # Use standard generation with enhanced prompt\n",
    "        input_ids = self.tokenizer.encode(enhanced_prompt)\n",
    "        generated = input_ids.copy()\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_length - len(input_ids)):\n",
    "                input_tensor = torch.tensor([generated], device=self.device)\n",
    "                outputs = self.model(input_tensor)\n",
    "                logits = outputs[0, -1, :]\n",
    "                \n",
    "                next_token = self.sampler.top_p_sample(logits, p=0.9, temperature=0.8)\n",
    "                generated.append(next_token)\n",
    "                \n",
    "                if next_token in [0, 1]:\n",
    "                    break\n",
    "        \n",
    "        return self.tokenizer.decode(generated)\n",
    "\n",
    "def demonstrate_controllable_generation():\n",
    "    \"\"\"Demonstrate various controllable generation techniques.\"\"\"\n",
    "    print(\"Demonstrating controllable generation techniques...\")\n",
    "    \n",
    "    model, tokenizer = create_demo_model()\n",
    "    sampler = AdvancedSampler(tokenizer)\n",
    "    controller = ControllableGenerator(model, tokenizer, sampler)\n",
    "    \n",
    "    base_prompt = \"Artificial intelligence\"\n",
    "    \n",
    "    print(f\"Base prompt: '{base_prompt}'\\n\")\n",
    "    \n",
    "    # Length control\n",
    "    print(\"=== Length Control ===\")\n",
    "    short_text = controller.generate_with_length_control(base_prompt, target_length=20)\n",
    "    medium_text = controller.generate_with_length_control(base_prompt, target_length=40)\n",
    "    long_text = controller.generate_with_length_control(base_prompt, target_length=60)\n",
    "    \n",
    "    print(f\"Short (20 tokens): {short_text}\")\n",
    "    print(f\"Medium (40 tokens): {medium_text}\")\n",
    "    print(f\"Long (60 tokens): {long_text}\")\n",
    "    \n",
    "    # Keyword control\n",
    "    print(\"\\n=== Keyword Control ===\")\n",
    "    keywords = ['innovation', 'future', 'technology']\n",
    "    keyword_text = controller.generate_with_keyword_control(base_prompt, keywords)\n",
    "    print(f\"With keywords {keywords}: {keyword_text}\")\n",
    "    \n",
    "    # Sentiment control\n",
    "    print(\"\\n=== Sentiment Control ===\")\n",
    "    positive_text = controller.generate_with_sentiment_control(base_prompt, 'positive')\n",
    "    negative_text = controller.generate_with_sentiment_control(base_prompt, 'negative')\n",
    "    \n",
    "    print(f\"Positive sentiment: {positive_text}\")\n",
    "    print(f\"Negative sentiment: {negative_text}\")\n",
    "    \n",
    "    # Format control\n",
    "    print(\"\\n=== Format Control ===\")\n",
    "    formats = ['list', 'question', 'summary', 'story']\n",
    "    \n",
    "    for fmt in formats:\n",
    "        formatted_text = controller.generate_with_format_control(base_prompt, fmt)\n",
    "        print(f\"{fmt.title()} format: {formatted_text}\")\n",
    "    \n",
    "    # Analysis of control effectiveness\n",
    "    print(\"\\n=== Control Effectiveness Analysis ===\")\n",
    "    \n",
    "    # Check keyword inclusion\n",
    "    keyword_count = sum(1 for kw in keywords if kw.lower() in keyword_text.lower())\n",
    "    print(f\"Keywords included: {keyword_count}/{len(keywords)}\")\n",
    "    \n",
    "    # Check length accuracy\n",
    "    short_length = len(short_text.split())\n",
    "    medium_length = len(medium_text.split())\n",
    "    long_length = len(long_text.split())\n",
    "    \n",
    "    print(f\"Length accuracy:\")\n",
    "    print(f\"  Short: {short_length} tokens (target: 20)\")\n",
    "    print(f\"  Medium: {medium_length} tokens (target: 40)\")\n",
    "    print(f\"  Long: {long_length} tokens (target: 60)\")\n",
    "    \n",
    "    return {\n",
    "        'length_control': [short_text, medium_text, long_text],\n",
    "        'keyword_control': keyword_text,\n",
    "        'sentiment_control': [positive_text, negative_text],\n",
    "        'format_control': {fmt: controller.generate_with_format_control(base_prompt, fmt) for fmt in formats}\n",
    "    }\n",
    "\n",
    "# Demonstrate controllable generation\n",
    "control_results = demonstrate_controllable_generation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Generation Techniques\n",
    "\n",
    "State-of-the-art generation techniques that push the boundaries of what's possible:\n",
    "\n",
    "### Advanced Techniques:\n",
    "1. **Speculative Decoding**: Generate multiple tokens per forward pass\n",
    "2. **Classifier-Free Guidance**: Guide generation without external classifiers\n",
    "3. **Tree-based Generation**: Explore multiple paths simultaneously\n",
    "4. **Multi-objective Generation**: Optimize for multiple criteria\n",
    "5. **Self-Correction**: Iteratively improve generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class AdvancedGenerationTechniques:\n",
    "    \"\"\"Implementation of advanced generation techniques.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, sampler):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sampler = sampler\n",
    "        self.device = next(model.parameters()).device\n",
    "    \n",
    "    def speculative_decoding(self, prompt: str, max_length: int = 100,\n",
    "                           draft_k: int = 3) -> str:\n",
    "        \"\"\"Speculative decoding for faster generation (simplified).\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        input_ids = self.tokenizer.encode(prompt)\n",
    "        generated = input_ids.copy()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            while len(generated) < max_length:\n",
    "                # Draft phase: generate k tokens quickly (simplified)\n",
    "                draft_tokens = []\n",
    "                temp_generated = generated.copy()\n",
    "                \n",
    "                for _ in range(draft_k):\n",
    "                    input_tensor = torch.tensor([temp_generated], device=self.device)\n",
    "                    outputs = self.model(input_tensor)\n",
    "                    logits = outputs[0, -1, :]\n",
    "                    \n",
    "                    # Use greedy for draft (fast)\n",
    "                    next_token = self.sampler.greedy_sample(logits)\n",
    "                    draft_tokens.append(next_token)\n",
    "                    temp_generated.append(next_token)\n",
    "                    \n",
    "                    if next_token in [0, 1]:\n",
    "                        break\n",
    "                \n",
    "                # Verification phase: check if draft tokens are acceptable\n",
    "                verified_tokens = []\n",
    "                for token in draft_tokens:\n",
    "                    input_tensor = torch.tensor([generated + verified_tokens], device=self.device)\n",
    "                    outputs = self.model(input_tensor)\n",
    "                    logits = outputs[0, -1, :]\n",
    "                    \n",
    "                    # Sample with higher quality\n",
    "                    quality_token = self.sampler.top_p_sample(logits, p=0.9, temperature=0.8)\n",
    "                    \n",
    "                    # Accept draft token with some probability\n",
    "                    if token == quality_token or np.random.random() < 0.7:\n",
    "                        verified_tokens.append(token)\n",
    "                    else:\n",
    "                        verified_tokens.append(quality_token)\n",
    "                        break  # Stop verification if we reject a token\n",
    "                \n",
    "                generated.extend(verified_tokens)\n",
    "                \n",
    "                if any(token in [0, 1] for token in verified_tokens):\n",
    "                    break\n",
    "        \n",
    "        return self.tokenizer.decode(generated)\n",
    "    \n",
    "    def tree_based_generation(self, prompt: str, max_length: int = 100,\n",
    "                            branching_factor: int = 3, depth: int = 3) -> List[str]:\n",
    "        \"\"\"Generate multiple candidate paths using tree search.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        input_ids = self.tokenizer.encode(prompt)\n",
    "        \n",
    "        # Tree node: (sequence, score, depth)\n",
    "        tree_nodes = [(input_ids, 0.0, 0)]\n",
    "        completed_paths = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            while tree_nodes and len(completed_paths) < 5:\n",
    "                new_nodes = []\n",
    "                \n",
    "                for sequence, score, current_depth in tree_nodes:\n",
    "                    if current_depth >= depth or len(sequence) >= max_length:\n",
    "                        completed_paths.append((sequence, score))\n",
    "                        continue\n",
    "                    \n",
    "                    # Generate branches\n",
    "                    input_tensor = torch.tensor([sequence], device=self.device)\n",
    "                    outputs = self.model(input_tensor)\n",
    "                    logits = outputs[0, -1, :]\n",
    "                    \n",
    "                    # Get top-k candidates for branching\n",
    "                    log_probs = F.log_softmax(logits, dim=-1)\n",
    "                    top_log_probs, top_indices = torch.topk(log_probs, branching_factor)\n",
    "                    \n",
    "                    for log_prob, token_id in zip(top_log_probs, top_indices):\n",
    "                        new_sequence = sequence + [token_id.item()]\n",
    "                        new_score = score + log_prob.item()\n",
    "                        new_nodes.append((new_sequence, new_score, current_depth + 1))\n",
    "                \n",
    "                # Keep only the best nodes to prevent explosion\n",
    "                new_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "                tree_nodes = new_nodes[:10]  # Keep top 10 nodes\n",
    "        \n",
    "        # Add remaining nodes to completed paths\n",
    "        completed_paths.extend([(seq, score) for seq, score, _ in tree_nodes])\n",
    "        \n",
    "        # Sort by score and convert to text\n",
    "        completed_paths.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [self.tokenizer.decode(seq) for seq, _ in completed_paths[:5]]\n",
    "    \n",
    "    def multi_objective_generation(self, prompt: str, objectives: Dict[str, float],\n",
    "                                 max_length: int = 100) -> str:\n",
    "        \"\"\"Generate text optimizing for multiple objectives.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        input_ids = self.tokenizer.encode(prompt)\n",
    "        generated = input_ids.copy()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step in range(max_length - len(input_ids)):\n",
    "                input_tensor = torch.tensor([generated], device=self.device)\n",
    "                outputs = self.model(input_tensor)\n",
    "                logits = outputs[0, -1, :]\n",
    "                \n",
    "                # Calculate multi-objective scores\n",
    "                adjusted_logits = logits.clone()\n",
    "                \n",
    "                # Objective 1: Fluency (model confidence)\n",
    "                if 'fluency' in objectives:\n",
    "                    fluency_weight = objectives['fluency']\n",
    "                    adjusted_logits += fluency_weight * logits\n",
    "                \n",
    "                # Objective 2: Diversity (avoid repetition)\n",
    "                if 'diversity' in objectives:\n",
    "                    diversity_weight = objectives['diversity']\n",
    "                    recent_tokens = generated[-10:]  # Last 10 tokens\n",
    "                    for token in set(recent_tokens):\n",
    "                        if token < len(adjusted_logits):\n",
    "                            adjusted_logits[token] -= diversity_weight\n",
    "                \n",
    "                # Objective 3: Relevance (boost topic-related words)\n",
    "                if 'relevance' in objectives:\n",
    "                    relevance_weight = objectives['relevance']\n",
    "                    topic_words = ['artificial', 'intelligence', 'technology', 'future']\n",
    "                    for word in topic_words:\n",
    "                        word_tokens = self.tokenizer.encode(word)\n",
    "                        for token in word_tokens:\n",
    "                            if token < len(adjusted_logits):\n",
    "                                adjusted_logits[token] += relevance_weight\n",
    "                \n",
    "                next_token = self.sampler.top_p_sample(adjusted_logits, p=0.9, temperature=0.8)\n",
    "                generated.append(next_token)\n",
    "                \n",
    "                if next_token in [0, 1]:\n",
    "                    break\n",
    "        \n",
    "        return self.tokenizer.decode(generated)\n",
    "    \n",
    "    def self_correction_generation(self, prompt: str, max_length: int = 100,\n",
    "                                 num_iterations: int = 3) -> List[str]:\n",
    "        \"\"\"Iteratively improve generated text through self-correction.\"\"\"\n",
    "        iterations = []\n",
    "        current_text = prompt\n",
    "        \n",
    "        for iteration in range(num_iterations):\n",
    "            # Generate continuation\n",
    "            input_ids = self.tokenizer.encode(current_text)\n",
    "            generated = input_ids.copy()\n",
    "            \n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                for _ in range(max_length - len(input_ids)):\n",
    "                    input_tensor = torch.tensor([generated], device=self.device)\n",
    "                    outputs = self.model(input_tensor)\n",
    "                    logits = outputs[0, -1, :]\n",
    "                    \n",
    "                    # Adjust sampling based on iteration\n",
    "                    temperature = 1.0 - (iteration * 0.2)  # Get more conservative\n",
    "                    p = 0.9 - (iteration * 0.1)  # Get more focused\n",
    "                    \n",
    "                    next_token = self.sampler.top_p_sample(logits, p=max(0.5, p), \n",
    "                                                         temperature=max(0.6, temperature))\n",
    "                    generated.append(next_token)\n",
    "                    \n",
    "                    if next_token in [0, 1]:\n",
    "                        break\n",
    "            \n",
    "            current_text = self.tokenizer.decode(generated)\n",
    "            iterations.append(current_text)\n",
    "            \n",
    "            # Simple \"correction\" - use the generated text as new prompt\n",
    "            # In practice, you'd use more sophisticated correction mechanisms\n",
    "        \n",
    "        return iterations\n",
    "\n",
    "def demonstrate_advanced_techniques():\n",
    "    \"\"\"Demonstrate advanced generation techniques.\"\"\"\n",
    "    print(\"Demonstrating advanced generation techniques...\")\n",
    "    \n",
    "    model, tokenizer = create_demo_model()\n",
    "    sampler = AdvancedSampler(tokenizer)\n",
    "    advanced_gen = AdvancedGenerationTechniques(model, tokenizer, sampler)\n",
    "    \n",
    "    prompt = \"The future of technology\"\n",
    "    \n",
    "    print(f\"Prompt: '{prompt}'\\n\")\n",
    "    \n",
    "    # Speculative decoding\n",
    "    print(\"=== Speculative Decoding ===\")\n",
    "    spec_text = advanced_gen.speculative_decoding(prompt, max_length=60)\n",
    "    print(f\"Speculative: {spec_text}\")\n",
    "    \n",
    "    # Tree-based generation\n",
    "    print(\"\\n=== Tree-based Generation ===\")\n",
    "    tree_texts = advanced_gen.tree_based_generation(prompt, max_length=50)\n",
    "    for i, text in enumerate(tree_texts[:3], 1):\n",
    "        print(f\"Path {i}: {text}\")\n",
    "    \n",
    "    # Multi-objective generation\n",
    "    print(\"\\n=== Multi-objective Generation ===\")\n",
    "    objectives_sets = [\n",
    "        {'fluency': 1.0, 'diversity': 0.5, 'relevance': 0.3},\n",
    "        {'fluency': 0.5, 'diversity': 1.0, 'relevance': 0.5},\n",
    "        {'fluency': 0.3, 'diversity': 0.3, 'relevance': 1.0}\n",
    "    ]\n",
    "    \n",
    "    for i, objectives in enumerate(objectives_sets, 1):\n",
    "        multi_text = advanced_gen.multi_objective_generation(prompt, objectives)\n",
    "        obj_desc = ', '.join([f\"{k}={v}\" for k, v in objectives.items()])\n",
    "        print(f\"Objectives {i} ({obj_desc}): {multi_text}\")\n",
    "    \n",
    "    # Self-correction generation\n",
    "    print(\"\\n=== Self-correction Generation ===\")\n",
    "    correction_iterations = advanced_gen.self_correction_generation(prompt, max_length=50)\n",
    "    for i, iteration in enumerate(correction_iterations, 1):\n",
    "        print(f\"Iteration {i}: {iteration}\")\n",
    "    \n",
    "    # Performance comparison\n",
    "    print(\"\\n=== Performance Analysis ===\")\n",
    "    evaluator = TextQualityEvaluator(model, tokenizer)\n",
    "    \n",
    "    techniques = {\n",
    "        'Speculative': spec_text,\n",
    "        'Tree-based': tree_texts[0] if tree_texts else \"\",\n",
    "        'Multi-objective': multi_text,\n",
    "        'Self-correction': correction_iterations[-1]\n",
    "    }\n",
    "    \n",
    "    for name, text in techniques.items():\n",
    "        if text:\n",
    "            metrics = evaluator.evaluate_text(text)\n",
    "            print(f\"{name}:\")\n",
    "            print(f\"  Perplexity: {metrics['perplexity']:.2f}\")\n",
    "            print(f\"  Distinct-1: {metrics['distinct_1']:.3f}\")\n",
    "            print(f\"  Coherence: {metrics['coherence']:.3f}\")\n",
    "            print(f\"  Length: {metrics['length']} tokens\")\n",
    "    \n",
    "    return {\n",
    "        'speculative': spec_text,\n",
    "        'tree_based': tree_texts,\n",
    "        'multi_objective': techniques['Multi-objective'],\n",
    "        'self_correction': correction_iterations\n",
    "    }\n",
    "\n",
    "# Demonstrate advanced techniques\n",
    "advanced_results = demonstrate_advanced_techniques()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Best Practices and Guidelines\n",
    "\n",
    "### Generation Quality Checklist:\n",
    "\n",
    "#### For High-Quality Generation:\n",
    "- ✅ Use appropriate sampling strategies for your use case\n",
    "- ✅ Implement proper length normalization in beam search\n",
    "- ✅ Apply repetition penalty to avoid redundant text\n",
    "- ✅ Monitor generation metrics (perplexity, diversity, coherence)\n",
    "- ✅ Use controllable generation for specific requirements\n",
    "\n",
    "#### Sampling Strategy Selection:\n",
    "1. **Greedy**: Use for deterministic, factual content\n",
    "2. **Top-k (k=5-50)**: Good balance for most applications\n",
    "3. **Top-p (p=0.9)**: Excellent default choice\n",
    "4. **Low temperature (0.7-0.8)**: For coherent, focused text\n",
    "5. **High temperature (1.2-1.5)**: For creative, diverse text\n",
    "\n",
    "#### Beam Search Guidelines:\n",
    "- **Beam size**: 3-10 for most applications\n",
    "- **Length penalty**: 0.6-1.0 (lower values favor longer sequences)\n",
    "- **Early stopping**: Enable for efficiency\n",
    "- **Diverse beam search**: Use when you need variety\n",
    "\n",
    "#### Quality Metrics Priority:\n",
    "1. **Fluency**: Most important for readability\n",
    "2. **Coherence**: Critical for long-form text\n",
    "3. **Relevance**: Essential for task-specific generation\n",
    "4. **Diversity**: Important for creative applications\n",
    "5. **Factuality**: Crucial for informational content\n",
    "\n",
    "### Common Pitfalls to Avoid:\n",
    "1. **Repetition loops**: Use repetition penalty and diverse sampling\n",
    "2. **Incoherent text**: Monitor coherence metrics and use appropriate sampling\n",
    "3. **Length bias**: Apply proper length normalization\n",
    "4. **Over-constraining**: Balance control with creativity\n",
    "5. **Ignoring quality metrics**: Always evaluate generated text\n",
    "\n",
    "### Recommended Pipeline:\n",
    "```python\n",
    "# 1. Choose appropriate sampling strategy\n",
    "sampler = AdvancedSampler(tokenizer)\n",
    "\n",
    "# 2. Configure generation parameters\n",
    "generation_config = {\n",
    "    'max_length': 100,\n",
    "    'temperature': 0.8,\n",
    "    'top_p': 0.9,\n",
    "    'repetition_penalty': 1.2\n",
    "}\n",
    "\n",
    "# 3. Generate with quality monitoring\n",
    "text = generate_with_strategy(model, tokenizer, sampler, prompt, **generation_config)\n",
    "\n",
    "# 4. Evaluate quality\n",
    "evaluator = TextQualityEvaluator(model, tokenizer)\n",
    "metrics = evaluator.evaluate_text(text)\n",
    "\n",
    "# 5. Apply post-processing if needed\n",
    "if metrics['coherence'] < 0.5:\n",
    "    # Try different sampling strategy or apply correction\n",
    "    pass\n",
    "```\n",
    "\n",
    "This completes our exploration of advanced generation techniques! These methods will help you generate high-quality, diverse, and controllable text from your transformer models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",\n",
   "name": "python3"\n  },\n  "language_info": {\n   "codemirror_mode": {\n    "name": "ipython",\n    "version": 3\n   },\n   "file_extension": ".py",\n   "mimetype": "text/x-python",\n   "name": "python",\n   "nbconvert_exporter": "python",\n   "pygments_lexer": "ipython3",\n   "version": "3.8.5"\n  }\n },\n "nbformat": 4,\n "nbformat_minor": 4\n}